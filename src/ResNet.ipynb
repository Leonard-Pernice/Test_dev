{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from MLDataTools.image_normalization import RandomDihedral\n",
    "from skimage.external import tifffile as tiff\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# torch setup\n",
    "# torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "# torch.set_default_tensor_type(torch.DoubleTensor) # so it doesnt throw a incompatible type exception\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # important for cloud compatability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard setup\n",
    "from datetime import datetime\n",
    "date = datetime.now().strftime(\"%Y-%m-%d.%H:%M:%S\")\n",
    "\n",
    "writer = SummaryWriter('tensorboardx/CIFAR10_ResNet50_'+date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.resnet18(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToImage:\n",
    "    def __call__(self, sample):\n",
    "        sample = torch.from_numpy(sample)\n",
    "        zeros = torch.zeros(1, 200, 200)\n",
    "        return torch.cat((sample, zeros))\n",
    "            \n",
    "class Denormalize:\n",
    "    def __init__(self, means, stdev):\n",
    "        self.means = means\n",
    "        self.stdev = stdev\n",
    "    def __call__(self, sample):\n",
    "        for dim in range(2):\n",
    "            sample[dim].mul_(self.stdev[dim]).add_(self.means[dim])\n",
    "        return sample\n",
    "\n",
    "class GetInfo:\n",
    "    def __init__(self, label=None):\n",
    "        self.label = label\n",
    "    def __call__(self, sample):\n",
    "        try:\n",
    "            print(sample.shape)\n",
    "        except: pass\n",
    "        finally:\n",
    "            if self.label: print(self.label)\n",
    "            print(type(sample))\n",
    "            return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_mean, resnet_stdev = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225] # visualize the images with this normalization\n",
    "\n",
    "ds_transforms = transforms.Compose([\n",
    "    transforms.Resize([224, 224]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=resnet_mean,\n",
    "                         std=resnet_stdev),\n",
    "    RandomDihedral(),\n",
    "])\n",
    "# use this for saving images later\n",
    "denormalize = Denormalize(means=resnet_mean,\n",
    "                     stdev=resnet_stdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets us control the datatype when the image is being read\n",
    "def tiff_read(path:str):\n",
    "    image = tiff.imread(path).astype(np.float)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 40\n",
    "DATA_ROOT = './CIFAR10_DATA'\n",
    "trainset = torchvision.datasets.CIFAR10(DATA_ROOT,train=True,transform=ds_transforms,download=True)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0) # run our of mem otherwise\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(DATA_ROOT,train=False,transform=ds_transforms, download=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "idx_to_class = {idx: value for idx, value in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 40\n",
    "# DATA_ROOT = '/home/user/HDev Dropbox/Projects/YNet_ready_data/yeast_v4'\n",
    "# trainset = torchvision.datasets.ImageFolder(DATA_ROOT+'/train', transform=ds_transforms, loader=tiff_read)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "\n",
    "# testset = torchvision.datasets.ImageFolder(DATA_ROOT+'/test', transform=ds_transforms, loader=tiff_read)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "# # invert class_to_id\n",
    "# idx_to_class = {v:k for k,v in trainset.class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing procedures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    net.train() # affects only modules like Dropout\n",
    "    trainiter = iter(trainloader)\n",
    "    for batch_idx, (data, targets) in enumerate(trainiter, 0):\n",
    "        # get the inputs\n",
    "\n",
    "        data, targets = Variable(data), Variable(targets)\n",
    "        l = data.size(0)\n",
    "\n",
    "        # backprop\n",
    "        optimizer.zero_grad() # dont forget to do that\n",
    "        output = net(data)\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step(loss)\n",
    "        \n",
    "        # tensorboard\n",
    "        global global_step\n",
    "        global_step += 1\n",
    "        writer.add_scalar('Train_Loss', loss.data.item(), global_step)\n",
    "        if batch_idx % 2 == 0: # every 2nd batch add to our embedding writer\n",
    "            #targets = targets.type(torch.DoubleTensor)\n",
    "            writer.add_embedding(output, metadata=targets.data, label_img=data.data, global_step=global_step)\n",
    "        if batch_idx % 20 == 0:\n",
    "            samples_done = batch_idx * BATCH_SIZE\n",
    "            percent = 100. * samples_done / len(trainloader.dataset)\n",
    "            print(f\"Train Epoch: {epoch} [{samples_done}/{len(trainloader.dataset)} \"\n",
    "                  f\"({percent:3.3}%)]\\tLoss: {loss.item():10.5}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_visualized= False \n",
    "def test(epoch): # include one-time visualization to check that the images are ok\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        test_loss = 0\n",
    "        wcases = [] # list of worst cases\n",
    "        classes_correct = list(0 for i in range(NUM_CLASSES))\n",
    "        classes_total = list(0 for i in range(NUM_CLASSES))\n",
    "        \n",
    "        for data, targets in iter(testloader):\n",
    "            # NOTE: UPDATE THIS LINE WHEN TORCH VERSION == 0.4\n",
    "            data, targets = Variable(data), Variable(targets)\n",
    "            \n",
    "            output = net(data)\n",
    "            # errors is a top 2 List[error:float, index of sample:int]\n",
    "            errors = worst_cases(output, targets)  \n",
    "            \n",
    "            for error, idx in errors:\n",
    "                target = targets[idx].data.item()\n",
    "                label = f\"{idx_to_class[target]}_{error:0.5}\"\n",
    "                tensor = data[idx]\n",
    "                wcases.append((tensor,label))\n",
    "            \n",
    "            # sum up batch loss\n",
    "            test_loss += criterion(output, targets).item()\n",
    "            \n",
    "            \n",
    "            # get the index of the max log-probability\n",
    "            _, pred = output.max(1) # returns a tuple the last element is the index Tensor\n",
    "            c = (pred == targets).squeeze()\n",
    "            l = c.size(0) # to account for different batch sizes\n",
    "            # this helps to identify which classes the network is struggling with\n",
    "            for i in range(l):\n",
    "                label = targets[i].item()\n",
    "                classes_correct[label] += c[i].item()\n",
    "                classes_total[label] += 1\n",
    "                        \n",
    "        writer.add_scalar('Test_Loss', test_loss, epoch)\n",
    "        test_loss /= len(testloader.dataset)\n",
    "        accuracy = 100. * (sum(classes_correct) / sum(classes_total))\n",
    "        \n",
    "        writer.add_scalar('Test_Accuracy',accuracy,global_step=epoch)\n",
    "        print(f\"\\nTest set: Average loss: {test_loss:6.5}, Accuracy: {accuracy:10.5}%\\n\")\n",
    "        \n",
    "        for i, total, correct in zip(range(NUM_CLASSES), classes_total, classes_correct):\n",
    "            cl = idx_to_class[i]\n",
    "            cl_accuracy = 100. * (classes_correct[i] / classes_total[i])\n",
    "            print(f\"class [{cl}]: accuracy {cl_accuracy:10.4}%\")\n",
    "        print()# prints a newline\n",
    "        \n",
    "        for image, label in wcases[:5]: # List[image:np.array, class:str]\n",
    "            # should be of dimensions (3, 200, 200)\n",
    "            denorm_image = denormalize(image)\n",
    "            writer.add_image(label, denorm_image, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helps to identify which cases the network was really wrong about\n",
    "def worst_cases(output: torch.Tensor, targets: torch.Tensor, top=2):\n",
    "    assert output.size(0) == targets.size(0)\n",
    "    length = output.size(0)\n",
    "    errors = []\n",
    "    for i in range(length):\n",
    "        z = torch.zeros(NUM_CLASSES)\n",
    "        label = targets[i].item()\n",
    "        z[label] = 1\n",
    "        diff = (output[i] - z).numpy().copy()\n",
    "        diff = np.sum(np.abs(diff))\n",
    "        errors.append((diff, i))\n",
    "        \n",
    "    errors.sort(key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "    return errors[:top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/50000 (0.0%)]\tLoss:     2.6437\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "global_step = 0\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    train(i)\n",
    "    test(i)\n",
    "    \n",
    "print(\"\\n Finished training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
