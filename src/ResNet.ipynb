{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from MLDataTools.image_normalization import RandomDihedral\n",
    "from skimage.external import tifffile as tiff\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import shutil\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from models.ResNetBuild import ResNet, BasicBlock\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# torch setup\n",
    "torch.set_default_tensor_type(torch.DoubleTensor) # so it doesnt throw a incompatible type exception\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # important for cloud compatability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard setup\n",
    "from datetime import datetime\n",
    "date = datetime.now().strftime(\"%Y-%m-%d.%H:%M:%S\")\n",
    "\n",
    "writer = SummaryWriter('tensorboardx/ResNet50_'+date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant definitions and global variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "NUM_CLASSES = 4\n",
    "ARCH = 'ResNet18'\n",
    "RESUME_TRAINING = False\n",
    "\n",
    "global_step = 0\n",
    "has_visualised = False\n",
    "best_accuracy = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddDimension:\n",
    "    def __init__(self, init_fn=torch.zeros):\n",
    "        self.init_fn = init_fn\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        size = sample.shape[-1] # assuming image is square with dims Channels x Width x Height\n",
    "        zeros = self.init_fn(1, size, size)\n",
    "        return torch.cat((sample, zeros))\n",
    "    \n",
    "# avoids a pytorch error: negative strides not supported in .from_numpy\n",
    "class ToTensorCopy:\n",
    "    def __call__(self,sample):\n",
    "        return torch.from_numpy(sample.copy())\n",
    "    \n",
    "class Denormalize:\n",
    "    def __init__(self, means, stdev):\n",
    "        self.means = means\n",
    "        self.stdev = stdev\n",
    "    def __call__(self, sample):\n",
    "        for dim in range(3):\n",
    "            sample[dim].mul_(self.stdev[dim]).add_(self.means[dim])\n",
    "        return sample\n",
    "\n",
    "class GetInfo: # useful for debugging\n",
    "    def __init__(self, label=None):\n",
    "        self.label = label\n",
    "    def __call__(self, sample):\n",
    "        try:\n",
    "            print(sample.shape)\n",
    "        except: pass\n",
    "        finally:\n",
    "            if self.label: print(self.label)\n",
    "            print(type(sample))\n",
    "            return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds_transforms = transforms.Compose([\n",
    "    RandomDihedral(), # doing this first gets rid of the negative stride error in .from_numpy\n",
    "    ToTensorCopy(),\n",
    "    #AddDimension(torch.zeros)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets us control the datatype when the image is being read\n",
    "def tiff_read(path: str):\n",
    "    image = tiff.imread(path).astype(np.double)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 40\n",
    "DATA_ROOT = '../datasets/yeast_ready'\n",
    "trainset = torchvision.datasets.ImageFolder(DATA_ROOT+'/train', transform=ds_transforms, loader=tiff_read)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(DATA_ROOT+'/test', transform=ds_transforms, loader=tiff_read)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_name: (mean, stdev)\n",
    "stats = {\n",
    "    'WT': ([48.37304926, 95.64728183],\n",
    "  [521.95544101, 310.77445807]),\n",
    "    'mfb1KO': ([ 47.58621839, 102.40188124],\n",
    "  [520.43241635, 311.95406937]),\n",
    "    'mfb1KO_mmr1KO': ([ 47.79873863, 100.28439551],\n",
    "  [517.82433373, 310.53787264]),\n",
    "    'mmr1KO': ([ 49.22677943, 110.97112597],\n",
    "  [522.00261751, 315.86275802])\n",
    "}\n",
    "\n",
    "# invert class_to_id\n",
    "idx_to_class = {v:k for k,v in trainset.class_to_idx.items()}\n",
    "norm_transforms = {} # class_id: normalization_transformation for that class\n",
    "for key, value in stats.items():\n",
    "    label = trainset.class_to_idx[key]\n",
    "    norm_transforms[label] = transforms.Normalize(value[0],value[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = models.resnet18(num_classes=NUM_CLASSES).to(device)\n",
    "net = ResNet(BasicBlock, [3, 4, 6, 3], num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename=f'{ARCH}.checkpoint.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, f'{ARCH}.best.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise(images: torch.Tensor,targets: torch.Tensor, num_images=2): # data[variable_len, 3, 224, 224]\n",
    "    for i in range(num_images):\n",
    "        image = images[i].clone().numpy()\n",
    "        scaler = MinMaxScaler()\n",
    "        for k in range(2):\n",
    "            figure, subplot, axes = tiff.imshow(image[k])\n",
    "            idx = targets[i].item()\n",
    "            c = idx_to_class[idx]\n",
    "            figure.suptitle(f'Images in the training data set, class: {c}', fontsize=15)\n",
    "            pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    net.train() # affects only modules like Dropout\n",
    "    trainiter = iter(trainloader)\n",
    "    for batch_idx, (data, targets) in enumerate(trainiter, 0):\n",
    "        for i, target in enumerate(targets, 0): # normalize the inputs according to class\n",
    "            t = norm_transforms[target.item()]\n",
    "            data[i, :2] = t(data[i, :2])\n",
    "        # visualize the data\n",
    "        global has_visualised\n",
    "        if not has_visualised: \n",
    "            visualise(data, targets)\n",
    "            has_visualised = True\n",
    "\n",
    "        # get the inputs\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        l = data.size(0)\n",
    "\n",
    "        # backprop\n",
    "        optimizer.zero_grad() # dont forget to do that\n",
    "        output = net(data)\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step(loss)\n",
    "        \n",
    "        # tensorboard\n",
    "        global global_step\n",
    "        global_step += 1\n",
    "        writer.add_scalar('Train_Loss', loss.data.item(), global_step)\n",
    "#         if batch_idx % 2 == 0: # every 2nd batch add to our embedding writer\n",
    "#             #targets = targets.type(torch.DoubleTensor)\n",
    "#             writer.add_embedding(output, metadata=targets.data, label_img=data.data, global_step=global_step)\n",
    "        if batch_idx % 20 == 0:\n",
    "            samples_done = batch_idx * BATCH_SIZE\n",
    "            percent = 100. * samples_done / len(trainloader.dataset)\n",
    "            print(f\"Train Epoch: {epoch} [{samples_done}/{len(trainloader.dataset)} \"\n",
    "                  f\"({percent:3.3}%)]\\tLoss: {loss.item():10.5}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch): # include one-time visualization to check that the images are ok\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        test_loss = 0\n",
    "        wcases = [] # list of worst cases\n",
    "        classes_correct = list(0 for i in range(NUM_CLASSES))\n",
    "        classes_total = list(0 for i in range(NUM_CLASSES))\n",
    "        \n",
    "        for data, targets in iter(testloader):\n",
    "            # NOTE: UPDATE THIS LINE WHEN TORCH VERSION == 0.4\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            \n",
    "            output = net(data)\n",
    "            \n",
    "            # errors is a top 2 List[error:float, index of sample:int]\n",
    "            new_cases = worst_cases(output, targets)  \n",
    "            wcases.extend(new_cases)\n",
    "            \n",
    "            # sum up batch loss\n",
    "            test_loss += criterion(output, targets).item()\n",
    "            \n",
    "            # get the index of the max log-probability\n",
    "            _, pred = output.max(1) # returns a tuple the last element is the index Tensor\n",
    "            c = (pred == targets).squeeze()\n",
    "            l = c.size(0) # to account for different batch sizes\n",
    "            # this helps to identify which classes the network is struggling with\n",
    "            for i in range(l):\n",
    "                label = targets[i].item()\n",
    "                classes_correct[label] += c[i].item()\n",
    "                classes_total[label] += 1\n",
    "                        \n",
    "        writer.add_scalar('Test_Loss', test_loss, epoch)\n",
    "        test_loss /= len(testloader.dataset)\n",
    "        accuracy = 100. * (sum(classes_correct) / sum(classes_total))\n",
    "        # models saving\n",
    "        if accuracy > best_accuracy:\n",
    "            is_best = True\n",
    "            best_accuracy = accuracy\n",
    "        else: is_best = False\n",
    "        \n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': ARCH,\n",
    "            'state_dict': net.state_dict(),\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best)\n",
    "        \n",
    "        writer.add_scalar('Test_Accuracy',accuracy,global_step=epoch)\n",
    "        print(f\"\\nTest set: Average loss: {test_loss:6.5}, Accuracy: {accuracy:10.5}%\\n\")\n",
    "        \n",
    "        # prints out accuracy per class\n",
    "        for i, total, correct in zip(range(NUM_CLASSES), classes_total, classes_correct):\n",
    "            cl = idx_to_class[i]\n",
    "            cl_accuracy = 100. * (classes_correct[i] / classes_total[i])\n",
    "            print(f\"class [{cl}]: accuracy {cl_accuracy:10.4}%\")\n",
    "            \n",
    "#         # saves worst cases to tensorboard\n",
    "#         for image, label in wcases[:5]: # List[image:np.array, class:str]\n",
    "#                 # should be of dimensions (3, 200, 200)\n",
    "#                 denorm_image = denormalize(image)\n",
    "#                 writer.add_image(label, denorm_image, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helps to identify which cases the network was really wrong about\n",
    "def worst_cases(data: torch.Tensor, targets: torch.Tensor, output: torch.Tensor, top=2):\n",
    "    assert output.size(0) == targets.size(0)\n",
    "    length = output.size(0)\n",
    "    errors = []\n",
    "    for i in range(length):\n",
    "        z = torch.zeros(NUM_CLASSES)\n",
    "        label = targets[i].item()\n",
    "        z[label] = 1\n",
    "        diff = (output[i] - z).numpy().copy()\n",
    "        diff = np.sum(np.abs(diff))\n",
    "        errors.append((diff, i))\n",
    "        \n",
    "    errors.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    for error, idx in errors[:top]: # append two new worst cases\n",
    "            target = targets[idx].data.item()\n",
    "            label = f\"{idx_to_class[target]}_{error:4.4}\"\n",
    "            tensor = data[idx]\n",
    "            wcases.append((tensor, label))\n",
    "            \n",
    "    return wcases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/609 (0.0%)]\tLoss:      3.235\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f603f9402244>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n Finished training.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-533c137e68b9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(EPOCHS):\n",
    "    train(i)\n",
    "    test(i)\n",
    "    \n",
    "print(\"\\n Finished training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
