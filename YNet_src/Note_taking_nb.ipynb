{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note-taking notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image-loading with tolerance for channel number:\n",
    "\n",
    "cv2 works for RGB and can conver to grayscale or tolerate 4 channels (Flags 1, 0 -1 respectively). This is problematic for loading images of more/less than these specified channels. \n",
    "\n",
    "skimage.external.tifffile functions are flexible in this extent. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage import io\n",
    "from skimage.external import tifffile\n",
    "from resources.conv_learner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.external import tifffile\n",
    "\n",
    "PATH = PATH = \"datasets/yeast_v1/\"\n",
    "\n",
    "testimg_cv2 = cv2.imread(PATH + 'train/WT/WT_WP_E1_S2_F1_I5_C5_A0.tif', 1)\n",
    "\n",
    "\n",
    "testimg_sk1 = tifffile.imread(PATH + 'train/WT/WT_WP_E1_S2_F1_I6_C1_A0.tif')\n",
    "testimg_sk2 = tifffile.imread(PATH + 'train/WT/WT_WP_E1_S2_F1_I6_C2_A0.tif')\n",
    "\n",
    "\n",
    "# plt.imshow(testimg_sk)\n",
    "print(testimg_cv2.shape)\n",
    "print(testimg_sk1.shape)\n",
    "\n",
    "\n",
    "### concatenating the two skimage-loaded images to test whether 4-channel tiff can be loaded:\n",
    "chan4 = np.concatenate((testimg_sk1, testimg_sk2), axis = 0)\n",
    "print(chan4.shape)\n",
    "\n",
    "tifffile.imsave(PATH + 'train/WT/temp.tif', chan4)\n",
    "\n",
    "testimg_fuse = tifffile.imread(PATH + 'train/WT/temp.tif')\n",
    "print(testimg_fuse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing image transformations with cv2 to find memory exhausting bug while running on yeast data with only 2 channels.\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage import io\n",
    "from skimage.external import tifffile\n",
    "\n",
    "PATH_yeast = \"datasets/yeast_v1/\"\n",
    "PATH_cifar10 = \"datasets/cifar10/\"\n",
    "\n",
    "test_bird_cv2 = cv2.imread(PATH_cifar10 + 'test/bird/25_bird.png').astype(np.float32)/255\n",
    "test_bird_cv2_RGB = cv2.cvtColor(test_bird_cv2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "test_yeast_io = io.imread(PATH_yeast + 'train/WT/WT_asymm.tif').astype(np.float32)/255\n",
    "\n",
    "print(test_bird_cv2.shape)\n",
    "print(test_bird_cv2_RGB.shape)\n",
    "print(test_yeast_io.shape)\n",
    "\n",
    "\n",
    "## io.imread loads the yeast images in order c,h,w - hence moveaxis(im, 0, -1) reorders correctly (?!)\n",
    "print(np.moveaxis(test_yeast_io, 0, -1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modified open_image function tests\n",
    "def imageloader(fn):\n",
    "    if str(fn).lower().endswith(('.tif', '.tiff', '.tifff')):\n",
    "        im = tifffile.imread(str(fn)).astype(np.float32)/255\n",
    "        im = np.moveaxis(im, 0, -1)\n",
    "        print('tif')\n",
    "    else:\n",
    "        im = cv2.imread(str(fn)).astype(np.float32)/255 \n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "        print('cv2')\n",
    "    if im is None: raise OSError(f'File not recognized by io.imread: {fn}') \n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_yeast_io = imageloader('datasets/yeast_v1/train/WT/WT_asymm.tif')\n",
    "test_bird_cv2 = imageloader('datasets/cifar10/test/bird/25_bird.png')\n",
    "\n",
    "print(test_yeast_io.shape)\n",
    "print(test_bird_cv2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing image plotting with matplotlib and denorm function in tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_yeast = \"datasets/yeast_v1/\"\n",
    "classes = ('WT', 'mfb1KO')\n",
    "stats = (np.array([ 0.4914 ,  0.48216]), np.array([ 0.24703,  0.24349]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sz,bs):\n",
    "    tfms = tfms_from_stats(stats, sz, aug_tfms=[RandomFlip()], pad=sz//8)\n",
    "    return ImageClassifierData.from_paths(PATH_yeast, val_name='test', tfms=tfms, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(200,4)\n",
    "x,y=next(iter(data.trn_dl))\n",
    "\n",
    "bla=data.trn_ds.denorm(x)[0,:,:,0]; print(bla.shape) #this triggers denorm() in dataset.py which includes an rollaxis()\n",
    "                                                     #which returns n,sz,sz,c instead of n,c,sz,sz!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = [2,200,200]\n",
    "x = torch.rand(3,*input_size)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset creation and normalization etc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to unzip and add more data \n",
    "import zipfile\n",
    "\n",
    "PATH = \"datasets/yeast_v2/\"\n",
    "\n",
    "# with zipfile as Zip ... might help with closing issues. \n",
    "for fnames in os.listdir(PATH):\n",
    "    zip_ref = zipfile.ZipFile(PATH + fnames, 'r')\n",
    "    f = str(fnames).split('.')[0] #parses the zip-file name from its extension to make corresponding folder.\n",
    "    os.mkdir(PATH + f)\n",
    "    zip_ref.extractall(PATH + f)\n",
    "    zip_ref.close()\n",
    "    \n",
    "print('All .zip files extracted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'yeast_v1_test_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-abf5aa58fc98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPATH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfnames\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'yeast_v1_test_data'"
     ]
    }
   ],
   "source": [
    "# calculate mean and std for train, test and potentially validation dataset\n",
    "\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from skimage.external import tifffile\n",
    "\n",
    "\n",
    "PATH = \"datasets/yeast_v2/\"\n",
    "\n",
    "\n",
    "for fnames in os.listdir(PATH):\n",
    "    images = []\n",
    "    if len(images) < 1:\n",
    "        images = io.imread(os.listdir(os.path.join(PATH, fnames))[0])\n",
    "    else:\n",
    "        for x in os.listdir(fnames):\n",
    "            images = np.stack(images, io.imread(PATH + fnames + '/' + x))\n",
    "\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfb1KO_WP_E1_S2_F1_I10_C15_A0.tif\n"
     ]
    }
   ],
   "source": [
    "fnames = os.listdir(PATH)\n",
    "Check = \n",
    "print(Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resources.conv_learner import *\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from skimage.external import tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resources.conv_learner import *\n",
    "PATH = \"datasets/yeast_v1/\"\n",
    "os.makedirs(PATH,exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With pytorch ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yeast_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.landmarks_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 1:].as_matrix()\n",
    "        landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "        sample = {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(*torch_dataset*, batch_size=140, shuffle=False, num_workers=4)\n",
    "\n",
    "pop_mean = []\n",
    "pop_std0 = []\n",
    "pop_std1 = []\n",
    "for i, data in enumerate(dataloader, 0):\n",
    "    # shape (batch_size, 3, height, width)\n",
    "    numpy_image = data['image'].numpy()\n",
    "    \n",
    "    # shape (3,)\n",
    "    batch_mean = np.mean(numpy_image, axis=(0,2,3))\n",
    "    batch_std0 = np.std(numpy_image, axis=(0,2,3))\n",
    "    batch_std1 = np.std(numpy_image, axis=(0,2,3), ddof=1)\n",
    "    \n",
    "    pop_mean.append(batch_mean)\n",
    "    pop_std0.append(batch_std0)\n",
    "    pop_std1.append(batch_std1)\n",
    "\n",
    "# shape (num_iterations, 3) -> (mean across 0th axis) -> shape (3,)\n",
    "pop_mean = np.array(pop_mean).mean(axis=0)\n",
    "pop_std0 = np.array(pop_std0).mean(axis=0)\n",
    "pop_std1 = np.array(pop_std1).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing normalize()\n",
    "x = test_bird_cv2\n",
    "\n",
    "stats = (np.array([ 0.4914 ,  0.48216,  0.44653]), np.array([ 0.24703,  0.24349,  0.26159]))\n",
    "\n",
    "m=stats[0]\n",
    "s=stats[1]\n",
    "\n",
    "m=np.array(m, dtype=np.float32)\n",
    "s=np.array(s, dtype=np.float32)\n",
    "\n",
    "#normalize() executing code test\n",
    "x = (x-m)/s\n",
    "\n",
    "print(m)\n",
    "print(s)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage import io\n",
    "from skimage.external import tifffile\n",
    "\n",
    "PATH_yeast = \"datasets/yeast_v1/\"\n",
    "PATH_cifar10 = \"datasets/cifar10/\"\n",
    "\n",
    "\n",
    "# testimg_sk1 = sk.io.imread(PATH_yeast + 'train/WT/WT_WP_E1_S2_F1_I6_C1_A0.tif')\n",
    "# testimg_sk2 = sk.io.imread(PATH_yeast + 'train/WT/WT_WP_E1_S2_F1_I6_C2_A0.tif')\n",
    "\n",
    "test_bird_cv2 = cv2.imread(PATH_cifar10 + 'test/bird/25_bird.png').astype(np.float32)/255\n",
    "\n",
    "test_bird = io.imread(PATH_cifar10 + 'test/bird/25_bird.png').astype(np.float32)/255 \n",
    "print(testimg_sk1.shape)\n",
    "print(test_bird.shape)\n",
    "print(test_bird_cv2.shape)\n",
    "\n",
    "### concatenating the two skimage-loaded images to test whether 4-channel tiff can be loaded:\n",
    "\n",
    "# chan4 = np.concatenate((testimg_sk1, testimg_sk2), axis = 0)\n",
    "# sk.io.imsave(PATH + 'train/WT/temp.tif', chan4)\n",
    "# tifffile.imsave(PATH + 'train/WT/temp.tif', chan4)\n",
    "\n",
    "# testimg_fuse_imageio = io.imread(PATH + 'train/WT/temp.tif')\n",
    "# testimg_fuse_tifffile = tifffile.imread(PATH + 'train/WT/temp.tif')\n",
    "\n",
    "# print(testimg_fuse_imageio.shape)\n",
    "# print(testimg_fuse_tifffile.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the read_dirs function in dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PATH = \"datasets/cifar10/\"\n",
    "folder = 'test' #within the function network, gets passed in automatically\n",
    "\n",
    "lbls, fnames, all_lbls = [], [], []\n",
    "full_path = os.path.join(PATH, folder)\n",
    "for lbl in sorted(os.listdir(full_path)):\n",
    "    if lbl not in ('.ipynb_checkpoints','.DS_Store'):\n",
    "        all_lbls.append(lbl)\n",
    "        for fname in os.listdir(os.path.join(full_path, lbl)):\n",
    "            if fname not in ('.DS_Store'):\n",
    "                fnames.append(os.path.join(folder, lbl, fname))\n",
    "                lbls.append(lbl)\n",
    "\n",
    "print(lbls[0:5])\n",
    "print(fnames[0:5])\n",
    "print(all_lbls[0:10])\n",
    "print(len(all_lbls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
