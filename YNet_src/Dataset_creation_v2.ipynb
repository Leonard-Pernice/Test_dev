{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset from .zip files and calc normalization statistics\n",
    "\n",
    "Step_1: create standard dataset to be re-used, either by creating folders or as hdf5 object. \n",
    "\n",
    "Step_2: calculate mean + std for train and test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cerber/repos/WPColumbia/YNet_dev\n",
      "205 images assigned to train\n",
      "35 images assigned to test\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'TempPath' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-520368096088>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Function call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mShuffleZip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-2c2e43aaad9f>\u001b[0m in \u001b[0;36mShuffleZip\u001b[0;34m(Dataset_name, input_path, output_path, val)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# zip shuffled images and store at output_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mzipup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_addrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_addrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_addrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m#     return ()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-c2255d886736>\u001b[0m in \u001b[0;36mzipup\u001b[0;34m(save_path, test_addrs, train_addrs, Dataset_name, val_addrs)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# writing each file one by one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maddrs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_addrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTempPath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0maddrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'All training images zipped successfully!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TempPath' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "# trying to unzip the \n",
    "# Unzips, shuffles, re-zips and stores file at specified output_path\n",
    "\n",
    "Dataset_name = 'mmr1KO_240'\n",
    "input_path = f'../datasets/original_zips/{Dataset_name}.zip'\n",
    "output_path = '../datasets/shuffled_zips/'\n",
    "\n",
    "# Function call:\n",
    "\n",
    "ShuffleZip(Dataset_name, input_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create shuffled dataset in zip-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195 images assigned to train\n",
      "35 images assigned to test\n",
      "All training images zipped successfully!\n",
      "All test images zipped successfully!\n",
      "Files moved to:datasets/Exp1_data_storage/shuffled_zips/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -> ShuffleZip and sub-functions\n",
    "\n",
    "# Unzips, shuffles, re-zips and stores file at specified output_path\n",
    "\n",
    "Dataset_name = 'mmm1KO_230'\n",
    "input_path = 'datasets/Exp1_data_storage/original_zips/mmm1KO_230.zip'\n",
    "output_path = 'datasets/Exp1_data_storage/shuffled_zips/'\n",
    "\n",
    "# Function call:\n",
    "\n",
    "ShuffleZip(Dataset_name, input_path, output_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Unzip pairs of train/test images from zip files to correct folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> ready_data function:\n",
    "\n",
    "# Unzips a pair (or trio if val is used) of train & test zip files according to dataset_name into a target folder;\n",
    "# creates, or respects folder structure according to:\n",
    "#\n",
    "# -folder\n",
    "#   |-train\n",
    "#      |-class_1\n",
    "#      |-class_2\n",
    "#   |-test\n",
    "#      |-class_1\n",
    "#      |-class_2\n",
    "\n",
    "Dataset_name = 'mmm1KO_230'\n",
    "input_path = 'datasets/Exp1_data_storage/shuffled_zips'\n",
    "output_path = 'datasets/yeast_v3/'\n",
    "\n",
    "ready_data(Dataset_name, input_path, output_path, data_struct = ['train', 'test'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Creating shuffled list of train, test and potentially validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShuffleZip(Dataset_name, input_path, output_path, val = False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to unzip, shuffle, re-zip and store a set of images at a specified location.\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "    Dataset_name: name of the dataset, e.g. WT_175 - should be descriptive \n",
    "    input_path: path to input .zip file\n",
    "    output_path: path for shuffled .zip-file to be stored\n",
    "\n",
    "    -> creates temp folder in same directory as .zip file to store unzipped files in, but deletes it once done. \n",
    "    -> shuffles and splits unzipped files between train, test and optionally val datasets.\n",
    "    -> optionally re-zip or storage in hdf5 object (TODO)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    import glob\n",
    "    import os\n",
    "    import zipfile\n",
    "\n",
    "\n",
    "\n",
    "    ### Arguments ###\n",
    "    # select cell designation, e.g. WT or mfb1KO - important for, well, naming... \n",
    "    Dataset_name = Dataset_name #don't add .zip here\n",
    "\n",
    "    # choose target .zip file\n",
    "    ZPath = input_path\n",
    "    \n",
    "    # chose path to save shuffled .zip at\n",
    "    save_path = output_path\n",
    "\n",
    "\n",
    "    ### Execution --------------------------------------------------------------------------------###\n",
    "    \n",
    "    TempPath = os.path.dirname(ZPath) + '/TEMP-' + Dataset_name # Path definition, also for later use\n",
    "    \n",
    "    # unzips files into temp folder\n",
    "    if os.path.exists(TempPath):\n",
    "        raise ValueError('temp folder already exists in directory; consider deleting and re-run')\n",
    "    else:\n",
    "        os.makedirs(TempPath)\n",
    "\n",
    "    zip_ref = zipfile.ZipFile(ZPath, 'r') \n",
    "    zip_ref.extractall(TempPath)\n",
    "    zip_ref.close()\n",
    "    \n",
    "    \n",
    "    ### shuffel images and zip\n",
    "    test_addrs, train_addrs = shuffle_images(TempPath)\n",
    "    \n",
    "    # zip shuffled images and store at output_path\n",
    "    zipup(save_path, test_addrs, train_addrs, Dataset_name, val_addrs = None)\n",
    "    \n",
    "#     return ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Shuffling images using random.sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def shuffle_images(TempPath, val = False):\n",
    "\n",
    "    import random\n",
    "    import os\n",
    "\n",
    "    random.seed(1) #reproducible randomness\n",
    "\n",
    "    ### OPTIONS ###\n",
    "    shuffle_data = True  # shuffle the addresses before saving\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### Execution --------------------------------------------------------------------------------###\n",
    "\n",
    "    # get list of files in TempPath\n",
    "    addrs = os.listdir(TempPath)\n",
    "\n",
    "    # create shuffled list\n",
    "    if shuffle_data:\n",
    "        addrs = random.sample(addrs, k = len(addrs)) #creates shuffled list by random sampling from original list.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Question: \n",
    "    Generating train, test and optionally val datasets - Question: should there be the same absolute number of test/val \n",
    "    images for each class or should the number vary depending on total number of images per class e.g. \n",
    "    20 test images for a total of 100 class A images, but 40 for a total of 200 class B images?   \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # # Divide the hata into 60% train, 20% test, and optionally 20% val\n",
    "    # train_addrs = addrs[0:int(0.8*len(addrs))]\n",
    "    # test_addrs = addrs[int(0.8*len(addrs)):]\n",
    "    # # val_addrs = addrs[int(0.6*len(addrs)):int(0.8*len(addrs))]\n",
    "\n",
    "    # Select == 35 images for test and optionally val datasets; put the rest into train\n",
    "    test_addrs = addrs[0:35]\n",
    "    train_addrs = addrs[35:]\n",
    "\n",
    "    print(str(len(train_addrs)) + ' images assigned to train')\n",
    "    print(str(len(test_addrs)) + ' images assigned to test')\n",
    "    \n",
    "    return test_addrs, train_addrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Creating .zip files from shuffled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zipup(save_path, test_addrs, train_addrs, Dataset_name, val_addrs = None):\n",
    "\n",
    "    # Creating .zip file of train, test and potentially validation images. \n",
    "\n",
    "    from zipfile import ZipFile\n",
    "    from os.path import basename #required to use in zipfile.Zipfile.write(file, basename(file)) to avoid completed path to be archived\n",
    "    import os\n",
    "    import shutil \n",
    "\n",
    "    # use for debugging\n",
    "    verbose = 0\n",
    "\n",
    "    save_path = 'datasets/Exp1_data_storage/shuffled_zips/'\n",
    "\n",
    "    # make subdirectory to store suffled zip files\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### processing train images: ###\n",
    "    if verbose:\n",
    "        print('Following files will be zipped:')\n",
    "        for addrs in train_addrs:\n",
    "            print(addrs)\n",
    "\n",
    "    # writing files to a zipfile\n",
    "    with ZipFile(save_path + Dataset_name + '_train_data.zip','w') as zip:\n",
    "        # writing each file one by one\n",
    "        for addrs in train_addrs:\n",
    "            zip.write(TempPath + '/' + addrs, basename(addrs))\n",
    "\n",
    "        print('All training images zipped successfully!')\n",
    "\n",
    "\n",
    "    ### processing Test images: ###\n",
    "    if verbose:\n",
    "        print('Following files will be zipped:')\n",
    "        for addrs in test_addrs:\n",
    "            print(addrs)\n",
    "\n",
    "    # writing files to a zipfile\n",
    "    with ZipFile(save_path + Dataset_name + '_test_data.zip','w') as zip:\n",
    "        # writing each file one by one\n",
    "        for addrs in test_addrs:\n",
    "            zip.write(TempPath + '/' + addrs, basename(addrs))\n",
    "\n",
    "        print('All test images zipped successfully!')\n",
    "\n",
    "#     zip_ref.close()\n",
    "\n",
    "    print('Files moved to:' + save_path)\n",
    "    \n",
    "#     return ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Unzips pairs (or trio's if val included) of shuffled images in zip files according to dataset_name and creates/stores images in train/test subfolder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ready_data(Dataset_name, input_path, output_path, data_struct = ['train', 'test']):\n",
    "\n",
    "    # To be used with shuffled data in zip files. \n",
    "    # Extracts these to specified dataset folder in train/test subfolders\n",
    "\n",
    "    import glob\n",
    "    import os\n",
    "    import zipfile\n",
    "\n",
    "    ### OPTIONS ###\n",
    "    \n",
    "    # select cell designation, e.g. WT or mfb1KO - important for, well, naming... \n",
    "    Dataset_name = Dataset_name\n",
    "    \n",
    "    # choose path where target zip-files are stored\n",
    "    ZPath = input_path\n",
    "    \n",
    "    # define path for files to be unzipped and stored in train and test directories\n",
    "    output_path = output_path\n",
    "\n",
    "    # optionally add 'val' keyword if datasets (zip files) have been created accordingly\n",
    "    data_struct = data_struct\n",
    "\n",
    "\n",
    "\n",
    "    ### Execution --------------------------------------------------------------------------------###\n",
    "\n",
    "    # unzips files correct folders or creates them\n",
    "\n",
    "    for i in data_struct:\n",
    "\n",
    "        if not os.path.exists(output_path + '/' + i):\n",
    "            os.makedirs(output_path + '/' + i)\n",
    "            print(i + ' created')\n",
    "            if not os.path.exists(output_path + '/' + i + Dataset_name):\n",
    "                os.makedirs(output_path + '/' + i + '/' + Dataset_name)\n",
    "                print(i + '/' + Dataset_name + ' created')\n",
    "            else:\n",
    "                raise ValueError('WARNING:' + i + '/' + Dataset_name + ' exists already - process cancelled to avoid overwriting')\n",
    "\n",
    "        zip_ref = zipfile.ZipFile(ZPath + '/' + Dataset_name + '_' + i + '_data.zip', 'r') \n",
    "        zip_ref.extractall(output_path + '/' + i + '/' + Dataset_name)\n",
    "        zip_ref.close()    \n",
    "        \n",
    "#         return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
