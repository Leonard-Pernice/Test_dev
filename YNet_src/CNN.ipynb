{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch, torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from models import CNN\n",
    "from pathlib import Path\n",
    "from MLDataTools.image_normalization import RandomDihedral\n",
    "from skimage.external import tifffile as tiff\n",
    "import numpy as np\n",
    "\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # important for cloud compatability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the train loader and the test loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '/Users/cerber/HDev Dropbox/Projects/YNet_ready_data/yeast_v4'\n",
    "data_path = Path(DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiff_read(path:str):\n",
    "    image = tiff.imread(path).astype(np.double)\n",
    "    return image\n",
    "\n",
    "class GetInfo:\n",
    "    def __init__(self, label=None):\n",
    "        self.label = label\n",
    "    def __call__(self, sample):\n",
    "        try:\n",
    "            print(sample.shape)\n",
    "        except: pass\n",
    "        finally:\n",
    "            if self.label: print(self.label)\n",
    "            print(type(sample))\n",
    "            return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_transforms = transforms.Compose([\n",
    "    RandomDihedral()\n",
    "])\n",
    "trainset = torchvision.datasets.ImageFolder(DATA_ROOT+'/train',transform=ds_transforms, loader=tiff_read)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=40, shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(DATA_ROOT+'/test', loader=tiff_read)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=40, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_name: (mean, stdev)\n",
    "stats = {\n",
    "    'WT': ([48.37304926, 95.64728183],\n",
    "  [521.95544101, 310.77445807]),\n",
    "    'mfb1KO': ([ 47.58621839, 102.40188124],\n",
    "  [520.43241635, 311.95406937]),\n",
    "    'mfb1KO_mmr1KO': ([ 47.79873863, 100.28439551],\n",
    "  [517.82433373, 310.53787264]),\n",
    "    'mmr1KO': ([ 49.22677943, 110.97112597],\n",
    "  [522.00261751, 315.86275802])\n",
    "}\n",
    "\n",
    "# invert class_to_id\n",
    "idx_to_class = {v:k for k,v in trainset.class_to_idx.items()}\n",
    "norm_transforms = {}\n",
    "for key, value in stats.items():\n",
    "    label = trainset.class_to_idx[key]\n",
    "    norm_transforms[label] = transforms.Normalize(value[0],value[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 16, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(32 * 47 * 47, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 32 * 47 * 47)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(epoch):\n",
    "    net.train() # affects only modules like Dropout\n",
    "    trainiter = iter(trainloader)\n",
    "    for batch_idx, (data, targets) in enumerate(trainiter, 0):\n",
    "        # get the inputs\n",
    "        for i, target in enumerate(targets, 0): # normalize the inputs according to class\n",
    "            t = norm_transforms[target.item()]\n",
    "            data[i] = t(data[i])\n",
    "\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad() # dont forget to do that\n",
    "        output = net(data)\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 5 == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(trainloader.dataset)} \"\n",
    "                  f\"({100. * batch_idx / len(trainloader)}%)]\\tLoss: {loss.item()}\")\n",
    "#\n",
    "# A simple test procedure to measure STN the performances on MNIST.\n",
    "#\n",
    "\n",
    "\n",
    "def test():\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for data, targets in iter(testloader):\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            for i, target in enumerate(targets, 0): # normalize the inputs according to class\n",
    "                t = norm_transforms[target.item()]\n",
    "                data[i] = t(data[i])\n",
    "            output = net(data)\n",
    "            # sum up batch loss\n",
    "            test_loss += criterion(output, targets).item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(targets.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(testloader.dataset)\n",
    "        print(f\"\\nTest set: Average loss: {test_loss:{5}}, Accuracy: {correct}/{len(testloader.dataset)}\"\n",
    "              f\" ({100. * correct / len(testloader.dataset):{5}}%)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/609 (0.0%)]\tLoss: 1.407597885071891\n",
      "Train Epoch: 0 [200/609 (31.25%)]\tLoss: 1.3810487205808046\n",
      "Train Epoch: 0 [400/609 (62.5%)]\tLoss: 1.2947981341883796\n",
      "Train Epoch: 0 [135/609 (93.75%)]\tLoss: 1.3485243313180173\n",
      "\n",
      "Test set: Average loss: 0.039941242079823705, Accuracy: 24/105 (22.857142857142858%)\n",
      "\n",
      "Train Epoch: 1 [0/609 (0.0%)]\tLoss: 1.328797571958806\n",
      "Train Epoch: 1 [200/609 (31.25%)]\tLoss: 1.4059843855310992\n",
      "Train Epoch: 1 [400/609 (62.5%)]\tLoss: 1.3980572087286187\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "for i in range(EPOCHS):\n",
    "    train(i)\n",
    "    test()\n",
    "    \n",
    "print(\"Finisehd training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
